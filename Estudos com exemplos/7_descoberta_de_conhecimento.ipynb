{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPzK+yPL8Kbh67Nbqb/TiYA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Exemplo 01 - NER com spaCy"],"metadata":{"id":"nn8DbRSwRLD8"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"E_lrjkPlOEJk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744331846601,"user_tz":180,"elapsed":19713,"user":{"displayName":"Hiago Gabriel Oliveira Pinto","userId":"08250887815262044914"}},"outputId":"8873cf57-f885-4dbb-b346-d6e7fbee4181"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.1)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n","Collecting pt-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pt-core-news-sm\n","Successfully installed pt-core-news-sm-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('pt_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["!pip install spacy\n","!python -m spacy download pt_core_news_sm"]},{"cell_type":"code","source":["import spacy\n","\n","# Carregando o modelo em português\n","nlp = spacy.load(\"pt_core_news_sm\")\n","\n","# Texto de exemplo\n","texto = \"Elon Musk, CEO da Tesla, visitou o Brasil em maio de 2022 para discutir investimentos de R$ 5 bilhões.\"\n","\n","# Processando o texto\n","doc = nlp(texto)\n","\n","# Imprimindo as entidades identificadas\n","for entidade in doc.ents:\n","    print(f\"{entidade.text} - {entidade.label_}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V1k4ohiGRv8e","executionInfo":{"status":"ok","timestamp":1744331858918,"user_tz":180,"elapsed":10140,"user":{"displayName":"Hiago Gabriel Oliveira Pinto","userId":"08250887815262044914"}},"outputId":"c7794f8c-7bff-4173-9216-56c72c995f23"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Elon Musk - LOC\n","Tesla - ORG\n","Brasil - LOC\n","R$ - MISC\n"]}]},{"cell_type":"markdown","source":["# Exemplo 02 - NER com NLTK"],"metadata":{"id":"-deWWBXTSGMc"}},{"cell_type":"code","source":["# Importando as bibliotecas necessárias para o reconhecimento de entidades nomeadas (NER)\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.tag import pos_tag\n","from nltk.chunk import ne_chunk\n","\n","# Baixando os pacotes necessários do NLTK\n","nltk.download('punkt_tab')  # Tokenização\n","nltk.download('maxent_ne_chunker_tab')  # Modelo para reconhecimento de entidades\n","nltk.download('words')  # Dicionário de palavras\n","nltk.download('averaged_perceptron_tagger_eng')  # Etiquetador de POS\n","\n","# Texto para análise de exemplo\n","texto = \"Barack Obama foi presidente dos Estados Unidos e ganhou o Prêmio Nobel da Paz.\"\n","\n","# Tokenizando o texto e identificando os rótulos de partes do discurso (POS)\n","tokens = word_tokenize(texto)  # Dividir o texto em palavras\n","tags = pos_tag(tokens)  # Identificar os rótulos POS\n","\n","# Identificando as entidades nomeadas no texto\n","entidades = ne_chunk(tags)  # Classificar e rotular entidades nomeadas\n","\n","# Exibindo as entidades reconhecidas\n","print(entidades)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ZkXyQZGSUAG","executionInfo":{"status":"ok","timestamp":1744332041797,"user_tz":180,"elapsed":627,"user":{"displayName":"Hiago Gabriel Oliveira Pinto","userId":"08250887815262044914"}},"outputId":"9ec17ffb-14a2-463a-a66c-b83b78e7cc1d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package maxent_ne_chunker_tab to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n","[nltk_data]       date!\n"]},{"output_type":"stream","name":"stdout","text":["(S\n","  (PERSON Barack/NNP)\n","  (ORGANIZATION Obama/NNP)\n","  foi/NN\n","  presidente/NN\n","  dos/NN\n","  (PERSON Estados/NNP Unidos/NNP)\n","  e/NN\n","  ganhou/NN\n","  o/NN\n","  (PERSON Prêmio/NNP Nobel/NNP)\n","  da/NN\n","  Paz/NNP\n","  ./.)\n"]}]},{"cell_type":"markdown","source":["# Exemplo 03 - Extração de Informações com Expressões Regulares"],"metadata":{"id":"4Gpw2Tm2SzNi"}},{"cell_type":"code","source":["# Importando a biblioteca de expressões regulares\n","import re\n","\n","# Texto de exemplo contendo uma data\n","texto = \"O pagamento deve ser feito até 30 de junho de 2025.\"\n","\n","# Criando uma expressão regular para identificar datas no formato específico\n","padrao = r\"\\d{1,2} de [a-zA-Z]+ de \\d{4}\"\n","datas = re.findall(padrao, texto)\n","\n","# Imprimindo a(s) data(s) identificada(s)\n","print(datas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E_sxTBpjS88j","executionInfo":{"status":"ok","timestamp":1744332150373,"user_tz":180,"elapsed":4,"user":{"displayName":"Hiago Gabriel Oliveira Pinto","userId":"08250887815262044914"}},"outputId":"92d1c5d1-c02e-4068-a306-38a748e3b162"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['30 de junho de 2025']\n"]}]},{"cell_type":"markdown","source":["# Exemplo 04 - Extração de Informações com Regras heurísticas e Dicionários"],"metadata":{"id":"nsLTgxR1TSe5"}},{"cell_type":"code","source":["# Criando uma lista com possíveis profissões\n","profissoes = [\"engenheiro\", \"cientista de dados\", \"médico\", \"advogado\"]\n","\n","# Texto de exemplo contendo informações sobre a profissão de uma pessoa\n","texto = \"João é engenheiro de software e trabalha na Tesla.\"\n","\n","# Verificando se alguma das profissões listadas está presente no texto\n","for profissao in profissoes:\n","    if profissao in texto:\n","        print(f\"Profissão identificada: {profissao}\")\n","\n","# Exemplo de saída esperada:\n","# Profissão identificada: engenheiro"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XXhvKFkBTDKZ","executionInfo":{"status":"ok","timestamp":1744332155170,"user_tz":180,"elapsed":11,"user":{"displayName":"Hiago Gabriel Oliveira Pinto","userId":"08250887815262044914"}},"outputId":"e90e702b-8d41-4f2e-e4d0-f3a631b51fde"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Profissão identificada: engenheiro\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"1HvBYQ4YTIYD"}},{"cell_type":"markdown","source":["# Exemplo 05 - Mineração de Textos com Frequência de Palavras e N-gramas"],"metadata":{"id":"uZmGgGGdTlid"}},{"cell_type":"code","source":["# Importando a biblioteca necessária\n","import nltk\n","from nltk.util import ngrams\n","from collections import Counter\n","\n","# Texto de exemplo para análise\n","texto = \"Mineração de textos envolve análise de palavras, palavras importantes e padrões.\"\n","\n","# Tokenizando o texto (transformando em palavras e padronizando para letras minúsculas)\n","palavras = nltk.word_tokenize(texto.lower())\n","\n","# Calculando as palavras mais frequentes\n","frequencia = Counter(palavras)\n","print(frequencia.most_common(5))  # Mostrando as 5 palavras mais frequentes\n","\n","# Gerando bigramas (duplas de palavras consecutivas)\n","bigrams = list(ngrams(palavras, 2))\n","print(bigrams)  # Exibindo os bigramas gerados"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jDyWeJV_T42g","executionInfo":{"status":"ok","timestamp":1744332406573,"user_tz":180,"elapsed":4,"user":{"displayName":"Hiago Gabriel Oliveira Pinto","userId":"08250887815262044914"}},"outputId":"de744b91-4fa5-4e8f-e897-3afe1b9eeaa9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[('de', 2), ('palavras', 2), ('mineração', 1), ('textos', 1), ('envolve', 1)]\n","[('mineração', 'de'), ('de', 'textos'), ('textos', 'envolve'), ('envolve', 'análise'), ('análise', 'de'), ('de', 'palavras'), ('palavras', ','), (',', 'palavras'), ('palavras', 'importantes'), ('importantes', 'e'), ('e', 'padrões'), ('padrões', '.')]\n"]}]},{"cell_type":"markdown","source":["# Exemplo 6 - Mineração de Texto"],"metadata":{"id":"u-JWcFJIUVWk"}},{"cell_type":"code","source":["# Instalando o Gensim\n","!pip install --upgrade --force-reinstall numpy\n","!pip install --upgrade --force-reinstall gensim\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"cJp7xK2CUZeP","executionInfo":{"status":"ok","timestamp":1744332905105,"user_tz":180,"elapsed":23342,"user":{"displayName":"Hiago Gabriel Oliveira Pinto","userId":"08250887815262044914"}},"outputId":"bb8f7e52-a5c0-4cad-9f81-418fff055b63"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy\n","  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.4 which is incompatible.\n","tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-2.2.4\n","Collecting gensim\n","  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n","Collecting numpy<2.0,>=1.18.5 (from gensim)\n","  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n","  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","Collecting smart-open>=1.8.1 (from gensim)\n","  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n","Collecting wrapt (from smart-open>=1.8.1->gensim)\n","  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n","Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n","Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n","Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n","Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n","Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.17.2\n","    Uninstalling wrapt-1.17.2:\n","      Successfully uninstalled wrapt-1.17.2\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.2.4\n","    Uninstalling numpy-2.2.4:\n","      Successfully uninstalled numpy-2.2.4\n","  Attempting uninstall: smart-open\n","    Found existing installation: smart-open 7.1.0\n","    Uninstalling smart-open-7.1.0:\n","      Successfully uninstalled smart-open-7.1.0\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.13.1\n","    Uninstalling scipy-1.13.1:\n","      Successfully uninstalled scipy-1.13.1\n","  Attempting uninstall: gensim\n","    Found existing installation: gensim 4.3.3\n","    Uninstalling gensim-4.3.3:\n","      Successfully uninstalled gensim-4.3.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0 wrapt-1.17.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["smart_open","wrapt"]},"id":"b1ff83be4f244b689b3ad95cf36f8a24"}},"metadata":{}}]},{"cell_type":"code","source":["# Importando os módulos necessários do Gensim\n","from gensim import corpora, models\n","\n","# Dados de exemplo para análise de documentos\n","documentos = [[\"mineração\", \"textos\", \"dados\"],\n","              [\"inteligência\", \"artificial\", \"aprendizado\"],\n","              [\"dados\", \"aprendizado\", \"estatística\"]]\n","\n","# Criando o dicionário e o corpus para modelagem\n","dicionario = corpora.Dictionary(documentos)\n","corpus = [dicionario.doc2bow(texto) for texto in documentos]\n","\n","# Aplicando o modelo LDA (Latent Dirichlet Allocation)\n","lda_modelo = models.LdaModel(corpus, num_topics=2, id2word=dicionario)\n","print(lda_modelo.print_topics())\n","\n","# Observação: Pode ser necessário aumentar o número de iterações para melhorar a convergência"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QX0TrdDOUfjr","executionInfo":{"status":"ok","timestamp":1744332943698,"user_tz":180,"elapsed":1184,"user":{"displayName":"Hiago Gabriel Oliveira Pinto","userId":"08250887815262044914"}},"outputId":"9bf90bd7-93b7-40c1-fd91-ff56197e6679"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"]},{"output_type":"stream","name":"stdout","text":["[(0, '0.210*\"dados\" + 0.180*\"mineração\" + 0.180*\"textos\" + 0.142*\"aprendizado\" + 0.100*\"inteligência\" + 0.098*\"estatística\" + 0.092*\"artificial\"'), (1, '0.228*\"aprendizado\" + 0.168*\"dados\" + 0.154*\"artificial\" + 0.149*\"estatística\" + 0.147*\"inteligência\" + 0.077*\"textos\" + 0.077*\"mineração\"')]\n"]}]}]}